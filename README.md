# DREAm: Dual-perspective Reasoning and Attribution-based Refinement for Conversational Query Rewriting

<img width="1515" height="1056" alt="image" src="https://github.com/lujiarui-iie/DREAm/blob/main/assets/framework.jpg" />

## üìñ Introduction
This repository contains the implementation of **DREAm** (*Dual-perspective Reasoning and Attribution-based Refinement*). We evaluate our method using two types of retrievers (BM25 and ANCE) on two Conversational QA benchmarks: **TopiOCQA** and **QReCC**.

## ‚öôÔ∏è Installation

Create a virtual environment and install the required dependencies.

```bash
conda create -n dream python==3.8
conda activate dream

# Install main packages
pip install torch==1.8.1 transformers==4.2.0 
pip install numpy==1.22 
pip install faiss-gpu==1.7.2 pyserini==0.16

# Install LLaMA-Factory
cd ./code/LLaMA-Factory
pip install -e .
```

## Data Pre-Processing

1. Download the passage collection

Two public datasets can be download from [QReCC]([url](https://github.com/apple/ml-qrecc)), [TopiOCQA]([url](https://github.com/McGill-NLP/topiocqa)),
We mainly evaluate our method using two types of retrievers: BM25 and ANCE on two Conversational QA benchmarks: TopiOCQA and QReCC.

ËøõÂÖ• `./index/preprocess/qrecc` Âíå `./index/preprocess/topiocqa` ÂàÜÂà´‰∏ãËΩΩ qrecc Âíå topiocqa ÁöÑÁõ∏ÂÖ≥Êï∞ÊçÆÔºàÂåÖÊã¨ passage Á≠âÔºâÔºåÁÑ∂ÂêéÁî® processing.py Â§ÑÁêÜ„ÄÇ

2. ÂæóÂà∞ bm25 Âíå dense
‰∏∫‰∫ÜÂæóÂà∞ bm25 Âíå dense Ê£ÄÁ¥¢Â∫ìÔºåÈúÄË¶ÅÂàÜÂà´ÊâßË°å `./index/preprocess/bm25` Âíå `./index/preprocess/dense` Êù•ÊûÑÈÄ†„ÄÇ
‰∏ãËΩΩ `./index/ad-hoc-ance-msmarco`Ôºöhttps://huggingface.co/3ricL/ad-hoc-ance-msmarco/tree/main
‰∏ãËΩΩ `./index/ance_checkpoint`Ôºöhttps://drive.google.com/drive/folders/13jKyMtpfg1nThOAZT3mSCCMXu95QK5GT?usp=sharing


## Training

1. Data Preparing
‰∏ãËΩΩÁªü‰∏ÄÂ§ÑÁêÜËøáÊ†ºÂºèÁöÑ Ôºàqrecc Âíå topiocqaÔºâtrain dataset Âíå test datasetÔºö
`https://drive.google.com/drive/folders/1fFWixFDgrxwzyftlX34I7MnkbrpmcXJs?usp=sharing` Âà∞ `./dataset`

‰∏ãËΩΩ deepseek ÁîüÊàêÁöÑÊÄùËÄÉËøáÁ®ãÂíåÈáçÂÜôÔºöhttps://drive.google.com/drive/folders/1UYq2bZRoA_Jl_VuAqBqtVFPcseDcEGuO?usp=sharing Âà∞ `./code/think_data`

ÊâßË°å `./code/data_processing/convert_lf_format.py` ËΩ¨Êç¢‰∏∫ LF ÊîØÊåÅÁöÑËÆ≠ÁªÉÊ†ºÂºè„ÄÇ

‰øÆÊîπ LLaMA-Factory ÁöÑ dataset_info.json ÂÜÖÂÆπ


2. Pruning
ÊØèÊ¨°Ââ™ÊûùÈúÄË¶ÅÊâßË°å `./utils/get_keyword.py` Âíå `./utils/pruning.py`
using Pruner, trained on original (non-pruned) dataset.

3. SFT
`./code/train_eval/train_sft.sh`

## üîé Inference & Evaluation

1. Inference

Generate rewrites using the trained model:

```bash
python ./code/train_eval/infer.py
```

2. Evaluation

Evaluate retrieval performance using Sparse (BM25) or Dense (ANCE) retrieval:

```bash
# Sparse Retrieval Evaluation
python ./code/train_eval/search_sparse.py

# Dense Retrieval Evaluation
python ./code/train_eval/search_dense.py
```

3. All-in-One Script

To run the entire pipeline (Training -> Inference -> Evaluation):

```bash
bash train_infer_eval.sh
```

## ü§ù Acknowledgments

We appreciate the open-source contributions from the following projects:

- [LLaMA-Factory]([url](https://github.com/hiyouga/LLaMA-Factory))
- [CHIQ]([url](https://github.com/fengranMark/CHIQ))
- [ConvGQR]([url](https://github.com/fengranMark/ConvGQR))
- [cs-shortcut]([url](https://github.com/naver-ai/cs-shortcut))